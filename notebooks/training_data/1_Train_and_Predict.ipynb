{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning using Sentinel-2 Data\n",
    "\n",
    "This example uses training data from the\n",
    "[Coast Train](https://github.com/nick-murray/coastTrain) dataset\n",
    "along with Sentinel-2 data to demonstrate how to use a\n",
    "machine learning classifier, in this case, Random Forest, to\n",
    "assign a class to each pixel.\n",
    "\n",
    "This notebook combines lessons from previous notebooks into\n",
    "a comprehensive worked example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "First we load the required Python libraries and tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload functions during development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from ldn.typology import colors, classes as classes_values\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data\n",
    "\n",
    "Load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training data\n",
    "training_data = gpd.read_file(\"training_data.geojson\")\n",
    "training_data = training_data[~training_data['outlier']] # Remove outliers from the training data\n",
    "training_data.drop(columns=['outlier'], inplace=True) # Drop outlier column as it's no longer needed\n",
    "class_attr = \"lulc\"\n",
    "\n",
    "training_data.explore(\n",
    "    column=class_attr,\n",
    "    categorical=True,\n",
    "    categories=(present_classes := sorted(training_data[class_attr].unique())),\n",
    "    cmap=[colors[c] for c in present_classes],\n",
    "    legend=True,\n",
    "    style_kwds={\"radius\": 6, \"fillOpacity\": 0.8, \"weight\": 0.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove geometry column for train/test split\n",
    "training_data = training_data.drop(columns=\"geometry\")\n",
    "\n",
    "print(len(training_data))\n",
    "\n",
    "# Split 70/30 into train/test. Splits the classes into train/test in a representative way.\n",
    "train_gdf, test_gdf = train_test_split(training_data, test_size=0.3, stratify=training_data[class_attr], random_state=42)\n",
    "\n",
    "print(f\"Training set class distribution:\\n{train_gdf[class_attr].value_counts()}\")\n",
    "print(f\"Test set class distribution:\\n{test_gdf[class_attr].value_counts()}\")\n",
    "print(train_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a classifier and fit a model\n",
    "\n",
    "We pass in simple numpy arrays to the classifier, one has the\n",
    "observations (the values of the red, green, blue and so on)\n",
    "while the other has the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The classes are the first column\n",
    "classes = np.array(train_gdf)[:, 0]\n",
    "print(f\"Classes: {classes}\")\n",
    "\n",
    "# The observation data is everything after the first column\n",
    "observations = np.array(train_gdf)[:, 1:]\n",
    "\n",
    "# Create a model...\n",
    "classifier = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# ...and fit it to the data\n",
    "model = classifier.fit(observations, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "\n",
    "feature_cols = [c for c in train_gdf.columns if c != class_attr]\n",
    "\n",
    "# TODO: Add MAD bands back in.\n",
    "low_importance = [\"smad\", \"bcmad\", \"emad\", \"blue\"]\n",
    "feature_cols_reduced = [f for f in feature_cols if f not in low_importance]\n",
    "\n",
    "X_train = train_gdf[feature_cols_reduced].values\n",
    "y_train = train_gdf[class_attr].values\n",
    "X_test = test_gdf[feature_cols_reduced].values\n",
    "y_test = test_gdf[class_attr].values\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=500, class_weight=\"balanced\", random_state=42)\n",
    "model = classifier.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Feature importance — drop noisy features\n",
    "importances = pd.Series(model.feature_importances_, index=feature_cols_reduced).sort_values(ascending=False)\n",
    "print(\"Feature importances:\")\n",
    "print(importances)\n",
    "# Feature importance is probably the most useful next step — it'll tell you which bands are actually helping and which are adding noise.\n",
    "\n",
    "target_names = [k for k, v in sorted(classes_values.items(), key=lambda x: x[1]) if v != 0]\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geomad_dem=xr.open_dataset('geomad_dem.tif',engine=\"rasterio\").astype(np.uint8).to_array().squeeze()\n",
    "geomad_dem = xr.open_dataset(\"geomad_dem.nc\")\n",
    "\n",
    "stack = np.stack([geomad_dem[f].values.flatten() for f in feature_cols], axis=1)\n",
    "stack = np.stack([geomad_dem[f].values.flatten() for f in feature_cols_reduced], axis=1)\n",
    "stack = np.nan_to_num(stack, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "\n",
    "predictions = model.predict(stack)\n",
    "\n",
    "# Reshape back to raster\n",
    "prediction_map = predictions.reshape(geomad_dem[feature_cols_reduced[0]].shape)\n",
    "\n",
    "# Wrap in DataArray\n",
    "predicted_da = xr.DataArray(\n",
    "    prediction_map,\n",
    "    coords={\"y\": geomad_dem.y, \"x\": geomad_dem.x},\n",
    "    dims=[\"y\", \"x\"],\n",
    "    name=\"lulc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise our results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from ipyleaflet import basemaps\n",
    "\n",
    "from odc.geo.xr import assign_crs\n",
    "\n",
    "predicted_da = assign_crs(predicted_da, crs=\"EPSG:6933\")\n",
    "\n",
    "class_indexes = list(colors.keys())\n",
    "cmap = ListedColormap([colors[c] for c in class_indexes])\n",
    "\n",
    "predicted_da.odc.explore(categories=class_indexes, cmap=cmap, legend=True, tiles=basemaps.Esri.WorldImagery)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aim for >80% accuracy. Don't just look at the confusion matrix, also look at the output map.\n",
    "\n",
    "Use a product for validation.\n",
    "One validation method for tuning and another for final measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "target_names = [k for k, v in sorted(classes_values.items(), key=lambda x: x[1]) if v != 0]\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "disp.plot(xticks_rotation=45, cmap=\"Blues\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldn-TK5rT0MB-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
